{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Using Relevant Features Found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESS**\n",
    "- In notebook 2, the relevant features were found for both the UCI madelon dataset, and the Cook madelon dataset.\n",
    "- Below, the classification models will be the same classification models used in the Benchmarking notebook (notebook 1). \n",
    "- The scores will then be compared to the raw classifiers used in the Benchmarking notebook.\n",
    "\n",
    "\n",
    "**RELEVANT FEATURES FOUND FROM FEATURE EXTRACTION (NOTEBOOK 2) (difficult to identify true Redundant features from true Informative features)**\n",
    "- *UCI Madelon* has a total of 20 relevant features: 28, 48, 64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433, 442, 451, 453, 455, 472, 475, and 493\n",
    "- *Cook Madelon* has a total of 20 relevant features: 257, 269, 308, 315, 336, 341, 395, 504, 526, 639, 681, 701, 724, 736, 769, 808, 829, 867, 920, and 956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "- Here, I loaded the data only using the relevant 20 features found in the two respective datasets.\n",
    "- UCI Madelon: All 2,000 samples are going to be used from the train set and only the 20 relevant features, instead of the original 500 features.\n",
    "- Josh's Madelon: All 220,000 samples will be used with only the 20 relevant features, instead of the original 1,000 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split the Data\n",
    "- ***UCI Madelon*** was not train test split, since the data on the website is already split into a train set and a test set. The data was imported above in the manner described under the **Load Data** section of this notebook where only the 20 relevant features are being used for both the train set and the test set provided by the website. \n",
    "- ***Cook's Madelon*** is passed through scikit learn's `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - Scale and Deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify and Score the Data Using the Same 4 Classification Models in Benchmarking (Notebook 1)\n",
    "- Calculate Test Scores aka Accuracy\n",
    "- Run Classification Reports\n",
    "- Run Confusion Matrices\n",
    "- Calculate LogLoss in each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
